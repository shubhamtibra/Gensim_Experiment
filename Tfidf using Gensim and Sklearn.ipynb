{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
      "[(0, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.44424552527467476), (5, 0.3244870206138555), (6, 0.44424552527467476), (7, 0.3244870206138555)]\n",
      "[(2, 0.5710059809418182), (5, 0.4170757362022777), (7, 0.4170757362022777), (8, 0.5710059809418182)]\n",
      "[(1, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)]\n",
      "[(3, 0.6282580468670046), (6, 0.6282580468670046), (7, 0.45889394536615247)]\n",
      "[(9, 1.0)]\n",
      "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
      "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
      "[(4, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "# Using Gensim\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "f = open(\"mycorpus.txt\")\n",
    "text = [[word for word in line.lower().split()] for line in f]\n",
    "        \n",
    "\n",
    "# Gensim implementation of TfIdf\n",
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        data_file = open(\"mycorpus.txt\")\n",
    "        for line in data_file:\n",
    "            yield dictionary.doc2bow(line.lower().split())\n",
    "\n",
    "\n",
    "from six import iteritems\n",
    "import itertools\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "dictionary = corpora.Dictionary(text)\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist\n",
    "            if stopword in dictionary.token2id]\n",
    "once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
    "dictionary.filter_tokens(stop_ids+once_ids)  # remove stop words and words that appear only once\n",
    "dictionary.compactify()  \n",
    "\n",
    "corpus = MyCorpus()\n",
    "test_corporus = open(\"mycorpus.txt\")\n",
    "\n",
    "tfidf = TfidfModel(corpus)\n",
    "\n",
    "for _corpus in corpus:\n",
    "    print(tfidf[_corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('system', 1), 0.3244870206138555)\n",
      "(('minors', 7), 0.695546419520037)\n",
      "(('eps', 3), 0.49182558987264147)\n",
      "(('trees', 7), 0.5080429008916749)\n",
      "(('trees', 6), 0.7071067811865475)\n",
      "(('user', 4), 0.45889394536615247)\n",
      "(('interface', 2), 0.5710059809418182)\n",
      "(('computer', 0), 0.5773502691896257)\n",
      "(('eps', 2), 0.5710059809418182)\n",
      "(('graph', 8), 0.45889394536615247)\n",
      "(('minors', 8), 0.6282580468670046)\n",
      "(('survey', 1), 0.44424552527467476)\n",
      "(('response', 1), 0.44424552527467476)\n",
      "(('time', 1), 0.44424552527467476)\n",
      "(('human', 3), 0.49182558987264147)\n",
      "(('system', 3), 0.7184811607083769)\n",
      "(('user', 2), 0.4170757362022777)\n",
      "(('response', 4), 0.6282580468670046)\n",
      "(('interface', 0), 0.5773502691896257)\n",
      "(('human', 0), 0.5773502691896257)\n",
      "(('graph', 7), 0.5080429008916749)\n",
      "(('time', 4), 0.6282580468670046)\n",
      "(('system', 2), 0.4170757362022777)\n",
      "(('trees', 5), 1.0)\n",
      "(('user', 1), 0.3244870206138555)\n",
      "(('survey', 8), 0.6282580468670046)\n",
      "(('computer', 1), 0.44424552527467476)\n",
      "(('graph', 6), 0.7071067811865475)\n"
     ]
    }
   ],
   "source": [
    "# Using pure python\n",
    "\n",
    "import math\n",
    "documents = [['human', 'interface', 'computer'],\n",
    " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
    " ['eps', 'user', 'interface', 'system'],\n",
    " ['system', 'human', 'system', 'eps'],\n",
    " ['user', 'response', 'time'],\n",
    " ['trees'],\n",
    " ['graph', 'trees'],\n",
    " ['graph', 'minors', 'trees'],\n",
    " ['graph', 'minors', 'survey']]\n",
    "words_freq = {}\n",
    "occurences = {}\n",
    "for i, j in enumerate(documents):\n",
    "    for k in j:\n",
    "        if k in words_freq and words_freq[k][1] != i:\n",
    "            words_freq[k][0] += 1\n",
    "            words_freq[k][1] = i\n",
    "            occurences[(k, i)] = 1\n",
    "        elif k in words_freq:\n",
    "            occurences[(k, i)] += 1\n",
    "        else:\n",
    "            words_freq[k] = [1, i]\n",
    "            occurences[(k, i)] = 1\n",
    "\n",
    "norm = [0 for i in range(9)]\n",
    "scores = {}\n",
    "for i in occurences:\n",
    "    scores[i] = occurences[i] * ((math.log(9/float(words_freq[i[0]][0]), 2.0)))\n",
    "    norm[i[1]] += scores[i]**2\n",
    "\n",
    "for i in scores:\n",
    "    print(i, scores[i]/ float(math.sqrt(norm[i[1]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57735027 0.         0.         0.57735027 0.57735027 0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.42593857 0.         0.         0.         0.         0.\n",
      "  0.42593857 0.42593857 0.37034129 0.42593857 0.         0.37034129]\n",
      " [0.         0.53361154 0.         0.         0.53361154 0.\n",
      "  0.         0.         0.46395983 0.         0.         0.46395983]\n",
      " [0.         0.44614767 0.         0.44614767 0.         0.\n",
      "  0.         0.         0.77582505 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.6023681  0.         0.         0.6023681  0.         0.52374168]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.         0.        ]\n",
      " [0.         0.         0.70710678 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.70710678 0.        ]\n",
      " [0.         0.         0.54859115 0.         0.         0.63094809\n",
      "  0.         0.         0.         0.         0.54859115 0.        ]\n",
      " [0.         0.         0.52374168 0.         0.         0.6023681\n",
      "  0.         0.6023681  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Using Scikit Learn\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\"human interface computer\",\n",
    " \"survey user computer system response time\",\n",
    " \"eps user interface system\",\n",
    " \"system human system eps\",\n",
    " \"user response time\",\n",
    " \"trees\",\n",
    " \"graph trees\",\n",
    " \"graph minors trees\",\n",
    " \"graph minors survey\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stoplist)\n",
    "\n",
    "X = vectorizer.fit_transform(documents)\n",
    "print(X.toarray())\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
